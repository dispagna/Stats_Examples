---
title: "Bayes R Packages Part 1"
author: "Melissa"
date: "11/2/2020"
output: 
  github_document:
    toc: true
    toc_depth: 2
---

# Introduction

The first course I took on Bayesian methods focused mostly on theory, and since the course was only one semester there wasn't time to learn about some of the software packages that are commonly used for Bayesian analysis.  This series of posts serves as an introduction to some of these R packages.

Since many people in my degree program were only familiar with R and SAS (and maybe a little Python), I think the following is an easy way to work up to _rstan_ which has a more C-like syntax:

1. rstanarm
    + Pro: Functions are syntactically very similar to frequentist functions with which users are already familiar.
    
    + Pro: Default priors are generally appropriate so the user isn't required to specify priors.
    
    + Con: The user isn't required to specify priors (i.e., caveat emptor).
  
2. rethinking
    + Pro: Uses the R formula syntax with which users are already familiar.
    
    + Pro: The user is required to specify all priors (i.e., no shortcuts).
    
    + Pro: You can get the rstan model out of the rethinking model, so this is a nice bridge between R and stan syntax.
    
    + Con: None that I've found yet, other than it's built on top of rstan so some folks might prefer to just go right to the source.  
  
3. rstan
    + Pro: It's the R interface to stan which is the Bayesian MCMC software that runs on multiple platforms and supports multiple languages.
  
    + Con: If you aren't familiar with C, Java or C++ then it's a completely new syntax to learn on top of the Bayesian concepts
  
# Approach

In general, a Bayesian model analysis includes the following steps:

1. Fit the model
2. Examine the prior predictive distribution
3. Examine diagnostic plots
4. Examine posterior distribution
5. Examine the posterior predictive distribution

In this post, I'll demonstrate each of these steps with the _rstanarm_ package. I'll do the same with _rethinking_ and _rstan_ in later posts.

# Setup Environment

First some basic R environment setup.

```{r results='hide', message=FALSE, warning=FALSE}
rm(list=ls())

library(tidyverse)
library(rstanarm)
library(bayesplot)
library(shinystan)
library(rstan)
library(gridExtra)

knitr::opts_chunk$set(out.width = "50%")
knitr::opts_chunk$set(fig.align = "center")
knitr::opts_chunk$set(message=FALSE)
knitr::opts_chunk$set(warning=FALSE)

options("scipen" = 1, "digits" = 4)

set.seed(123)
```

# Define the Model

I'll use the mtcars dataset. 

```{r}
library(datasets)
data(mtcars)
head(mtcars)
```

To keep things simple, I'm interested in a model with response _mpg_ and predictor _disp_. Let's plot the parameters of interest.

```{r}
mtcars %>%
  ggplot(aes(x=disp, y=mpg)) +
  geom_point(aes(color=factor(cyl))) +
  stat_smooth(method="lm")
```

Clearly a linear model isn't a great fit to the data; a spline would be more appropriate. I'll demonstrate both models in this post.

Before I start fitting models, I'll calculate the mean and standard deviation of both _mpg_ and _disp_ since I'll need this information later.

```{r}
mu <- mtcars %>% select(mpg, disp) %>% colMeans()
sigma <- mtcars %>% select(mpg, disp) %>% apply(2,sd)

knitr::kable(cbind(mu, sigma), col.names = c("Mean", "Std Dev"))
```

# Linear Model with Default Priors

Even though it's clear from the plot above that a linear model isn't going to be a great fit to the data, let's start with that to keep things simple:

\begin{align*}
  mpg \sim N(\mu, \sigma^2) \\
  \mu = a + b*disp \\
\end{align*}

The _stan_glm_ function from the _rstanarm_ package fits a Bayesian linear model.  The syntax is very similar to _lm_.

I'll start by fitting a model with the default priors.  When using the default priors, _stan_glm_ automatically standardizes the parameters. 

```{r results='hide'}
mdl1 <- stan_glm(mpg ~ disp, data = mtcars, cores=2)
```

## Prior Predictive Distribution

Next, I'll examine the prior predictive distribution to see if the default priors seem reasonable.  The _prior_summary_ function shows the default priors for the model as well as the adjusted priors after automatic scaling.  See http://mc-stan.org/rstanarm/articles/priors.html if you are interested in the details about how the default and adjusted priors are calculated. 

```{r}
prior_summary(mdl1)
```


```{r}
# Plot prior predictive distribution using adjusted priors
N <- 100

prior_samples <- data.frame(a = rnorm(N, 20, 15),
                            b = rnorm(N, 0, 0.12))

D <- seq(min(mtcars$disp), max(mtcars$disp), length.out = N)

res <- as.data.frame(apply(prior_samples, 1, function(x) x[1] + x[2] * (D-230.7))) %>%
  mutate(disp = D) %>%
  pivot_longer(cols=c(-"disp"), names_to="iter") 

res %>%
  ggplot() +
  geom_line(aes(x=disp, y=value, group=iter), alpha=0.2) +
  labs(x="disp", y="prior predictive mpg")
```

Two observations from this plot stand out: 1) negative mpg is unrealistic and 2) increasing mpg as displacement increases also seems unlikely in the real-world. Later on I'll choose a more informative prior that incorporates this additional knowledge. However the adjusted default priors aren't totally unreasonable so I'll proceed with the analysis.

## Diagnostic Plots

Once the model has been fit, either _as.matrix_ or _as.array_ extracts the posterior draws.  The key difference is that _as.array_ keeps the chains separate.

```{r}
post <- as.array(mdl1)
str(post)
```

Note that the default is four chains but that can be changed with the _chains_ argument in _stan_glm_.

### Trace Plots

The _bayesplot_ package provides the function _mcmc_trace_ which plots the MCMC draws.

```{r}
mcmc_trace(post, pars=c("disp", "sigma"))
```
There are three things I am looking for in the trace plot of each chain:

  1. *Good mixing* -  In other words, the chain is rapidly changing values across the full region versus getting "stuck" near a particular value and slowly changing.
  
  2. *Stationarity* - The mean of the chain is relatively stable.
  
  3. *Convergence* - All of the chains spend most of the time around the same high-probability value.
    
The trace plots above look good.  However, sometimes it can be hard to tell when there are multiple chains overlaid on the same plot, so two alternatives are shown below.

### Trace Plots with _ggplot2_

One alternative is to manually plot each chain separately.  Here's one way to do it with _ggplot2_.

```{r}
library(gridExtra)

pars <- c("disp", "sigma")

plts <- list()
for (par in pars)
{
  df <- as.data.frame(post[,,par]) %>%
    mutate(iteration = row_number()) %>%
    pivot_longer(cols=c(-"iteration"), values_to="value", names_to="chain")

  plts[[par]] <- df %>%
    ggplot() +
    geom_line(mapping=aes(x=iteration, y=value), color="blue") +
    facet_wrap(~chain, ncol=1) +
    labs(title=par)
}

grid.arrange(grobs=plts, nrow=1)
```

### Trace Rank Plot

Another alternative is the _mcmc_rank_overlay_ function.  This function plots a trace rank plot which is the distribution of the ranked samples.

```{r}
mcmc_rank_overlay(mdl1, pars=c("disp", "sigma"))
```

### Effective Sample Size

Since MCMC samples are usually correlated, the effective sample size (_n_eff_) is often less than the number of samples. There is no hard and fast rule for what is an acceptable number for _n_eff_. McElreath’s guidance is it depends on what you are trying to estimate. If you are interested mostly in the posterior mean, then _n_eff_ = 200 can be enough. But if you are interested in the tails of the distribution and it’s highly skewed then you’ll need _n_eff_ to be much larger. There are two parameters, _iter_ and _warmup_, which you can adjust in _stan_glm_ if a larger _n_eff_ is needed.

The _summary_ function displays _n_eff_ (and a lot of other information) for the object returned by _stan_glm_.

```{r}
summary(mdl1)
```

## Posterior Distribution

Since the chains and _n_eff_ look good, I'll examine the posterior distribution next. The Bayesian posterior point estimates for _a_ and _b_ are shown below.
```{r}
coef(mdl1)
```

The 89% credible intervals for all _a_, _b_ and _sigma_ are shown below. Why 89%?  Why not?  (See p56 of _Statistical Rethinking_ for McElreath's thoughts on this.)

```{r}
knitr::kable(posterior_interval(mdl1, prob=0.89))
```

### Posterior Predictive Distribution

Finally, I'll check the posterior predictive distribution.  The _posterior_predict_ function draws samples from the posterior predictive distribution. I do some manipulation of the dataframe to display boxplots of the posterior draws (car type ordered by increasing _disp_) and then overlay the observed _mpg_ in red.

```{r}
library(forcats)

post <- posterior_predict(mdl1) %>%
  apply(2, fivenum) %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column(var="car")

dat <- mtcars %>%
  select(c("mpg", "disp")) %>%
  rownames_to_column(var="car")

plyr::join(dat, post, by="car") %>%
  ggplot(aes(x=fct_reorder(car, disp))) +
  geom_boxplot(mapping=aes(ymin=V1, lower=V2, middle=V3, upper=V4, ymax=V5),
               stat="identity",
               outlier.shape = NA) +
  geom_point(mapping=aes(y=mpg), color="red") +
  theme(axis.text.x = element_text(angle = 90))
```

Unsurprisingly, this model doesn't predict the observed data all that well.

Another useful visualization is the expectation of the posterior predictive distribution (i.e., $\mu$). The _posterior_linpred_ function returns the linear predictor, possibly transformed by the inverse-link function.  The _posterior_epred_ function returns the expectation over the posterior predictive distribution. In this case, the model is a Gaussian likelihood with an identity link function, so the two functions return identical results.

```{r}
newdata <- data.frame(disp=seq(min(mtcars$disp), max(mtcars$disp)))

y_rep <- as.data.frame(t(posterior_linpred(mdl1, newdata=newdata, draws=50))) %>%
  cbind(newdata) %>%
  pivot_longer(cols=starts_with("V"), names_to="grp", values_to="mpg")

y_rep %>%
  ggplot(aes(x=disp, y=mpg)) +
  geom_line(aes(group=grp), alpha=0.2) +
  geom_point(data = mtcars, aes(color=factor(cyl))) 
```

Note that this plot looks very similar to a frequentist confidence interval.

# Linear Model with User-Specified Priors

Now I'll specify priors instead of using the defaults.  First, I'll standardize both _mpg_ and _disp_ since that will make it a bit easier to choose the priors. This time I'll choose a prior for the slope that is centered at -1 rather than at 0; you'll see the effect in the prior predictive distribution.

```{r results='hide'}
# Standardize
df <- data.frame(mtcars %>% select(mpg, disp) %>% scale())
df['cyl'] = mtcars$cyl

mdl2 <- stan_glm(mpg ~ disp, data = df,
                 prior = normal(-1,1/sqrt(2)), # prior for slope
                 prior_intercept = normal(0,1/sqrt(2)), # prior for intercept
                 cores=2)
```

### Prior Predictive Distribution

```{r include=FALSE, echo=FALSE}

# Alternative method for plotting prior predictive distribution
mdl2_prior_pred <- stan_glm(mpg ~ disp, data = df,
                 prior = normal(-1,1/sqrt(2)), # prior for slope
                 prior_intercept = normal(0,1/sqrt(2)), # prior for intercept
                 prior_PD = TRUE,
                 cores=2)

N <- 100

D <- seq(min(df$disp), max(df$disp), length.out = N)

prior_pred <- data.frame(t(posterior_epred(mdl2_prior_pred,
                                newdata=data.frame(disp=D),
                                draws=N)))

tmp <- prior_pred %>%
  mutate(disp = D)%>%
  pivot_longer(cols=-"disp", names_to="iter", values_to="mpg") 

tmp %>%
  ggplot() +
  geom_line(mapping=aes(x=disp, y=mpg, group=iter), alpha=0.2) +
  geom_point(data=df, mapping=aes(x=disp, y=mpg, color=factor(cyl)))
```



Again, I'll do a sanity check with the prior predictive distribution.

```{r}
prior_summary(mdl2)
```

```{r}
# Plot prior predictive distribution
N <- 100

prior_samples <- data.frame(a = rnorm(N, 0, 1/sqrt(2)),
                            b = rnorm(N, -1, 1/sqrt(2)))

D <- seq(min(df$disp), max(df$disp), length.out = N)

res <- as.data.frame(apply(prior_samples, 1, function(x) x[1] + x[2] * (D))) %>%
  mutate(disp = D) %>%
  pivot_longer(cols=c(-"disp"), names_to="iter") 

res %>%
  ggplot() +
  geom_line(aes(x=disp, y=value, group=iter), alpha=0.2) +
  labs(x="disp", y="prior predictive mpg")
```

Remember, I standardized _mpg_ & _disp_ so that's why the scales are different in this plot. Notice now that most of the time _mpg_ decreases as _disp_ increases; this is because the prior I chose for _b_ is no longer symmetric about 0. I'm using previous knowledge to make the prior more informative. Ideally, I might want to choose a prior that further constrains $b <= 0$ (e.g., Uniform(-1,0) or -Exponential(5)). However, this is one of the limitation of _rstanarm_--only certain distributions are supported for user-specified priors. The _rethinking_ and _rstan_ packages have greater flexibility in that regard as I'll demonstrate in another post.

### Diagnostic Plots

```{r}
post <- as.array(mdl2)
mcmc_trace(post, pars=c("disp", "sigma"))
```

```{r}
summary(mdl2)
```

The chains and _n_eff_ all look good.

### Posterior Distribution

The posterior estimates:

```{r}
coef(mdl2)
```

And the 89% posterior credible intervals:

```{r}
posterior_interval(mdl2, prob=0.89)
```

Remember the above are standardized, so I'll convert back to the orginal scale and compare to the results using the defaults priors.

```{r}
a_prime <- mu['mpg'] + sigma['mpg']*coef(mdl2)[1] - coef(mdl2)[2] * sigma['mpg'] * mu['disp'] / sigma['disp']
b_prime <- coef(mdl2)[2]*sigma['mpg'] / sigma['disp']

knitr::kable(cbind(coef(mdl1), c(a_prime, b_prime)), 
             col.names = c("Default", "User-Specified"))
```

The results are very similar; turns out there is enough data that the different priors really don't make much difference.

### Posterior Predictive Distribution

Finally, let's check the posterior predictive distribution:

```{r}
library(forcats)

post <- posterior_predict(mdl2) %>%
  apply(2, fivenum) %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column(var="car")

dat <- df %>%
  rownames_to_column(var="car") 

plyr::join(dat, post, by="car") %>%
  ggplot(aes(x=fct_reorder(car, disp))) +
  geom_boxplot(mapping=aes(ymin=V1, lower=V2, middle=V3, upper=V4, ymax=V5),
               stat="identity",
               outlier.shape = NA) +
  geom_point(mapping=aes(y=mpg), color="red") +
  theme(axis.text.x = element_text(angle = 90))
```

And the expectation over the posterior predictive distribution:

```{r}
newdata <- data.frame(disp=seq(min(df$disp), max(df$disp)))

y_rep <- as.data.frame(t(posterior_linpred(mdl2, newdata=newdata, draws=50))) %>%
  cbind(newdata) %>%
  pivot_longer(cols=starts_with("V"), names_to="grp", values_to="mpg")

y_rep %>%
  ggplot(aes(x=disp, y=mpg)) +
  geom_line(aes(group=grp), alpha=0.2) +
  geom_point(data = df, aes(color=factor(cyl))) 
```

The results are very similar to those with the default priors.  

# Generalized Additive Model

The linear model is a poor choice for this data, so I'll try a model with splines next. The _stan_gamm4_ function from the _rstanarm_ package fits Bayesian nonlinear (and mixed) models.  Again, the syntax is very similar to _gamm4_.

```{r results='hide'}
mdl3 <- stan_gamm4(mpg ~ s(disp, bs="cr", k=7), 
                   data = mtcars, 
                   cores=2, 
                   adapt_delta = 0.99)
```

## Prior Predictive Distribution

Unlike the linear model, it's not as straightforward to manually construct the prior predictive distribution.  Fortunately, _rstanarm_ will automatically generate it for us--we refit the model _without_ conditioning on the data by setting _prior_PD = TRUE_.

```{r results="hide"}
mdl3_prior_pred <- stan_gamm4(mpg ~ s(disp, bs="cr", k=7), 
                   data = mtcars, 
                   cores=2, 
                   prior_PD = TRUE,
                   adapt_delta = 0.99)
```

```{r}
N <- 50

D <- seq(min(mtcars$disp), max(mtcars$disp), length.out = N)

prior_pred <- data.frame(t(posterior_epred(mdl3_prior_pred,
                                newdata=data.frame(disp=D),
                                draws=N)))

tmp <- prior_pred %>%
  mutate(disp = D)%>%
  pivot_longer(cols=-"disp", names_to="iter", values_to="mpg") 

tmp %>%
  ggplot() +
  geom_line(mapping=aes(x=disp, y=mpg, group=iter), alpha=0.2) +
  geom_point(data=mtcars, mapping=aes(x=disp, y=mpg, color=factor(cyl)))
```


## Diagnostic Plots

```{r}
post <- as.array(mdl3)
mcmc_trace(post, regex_pars=c("disp", "sigma"))
```

```{r}
summary(mdl3)
```

The chains and _n_eff_ look good.

## Posterior Predictive Distribution

And finally, the posterior predictive distribution:

```{r}
library(forcats)

post <- posterior_predict(mdl3) %>%
  apply(2, fivenum) %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column(var="car")

dat <- mtcars %>%
  select(c("mpg", "disp")) %>%
  rownames_to_column(var="car")

plyr::join(dat, post, by="car") %>%
  ggplot(aes(x=fct_reorder(car, disp))) +
  geom_boxplot(mapping=aes(ymin=V1, lower=V2, middle=V3, upper=V4, ymax=V5),
               stat="identity",
               outlier.shape = NA) +
  geom_point(mapping=aes(y=mpg), color="red") +
  theme(axis.text.x = element_text(angle = 90))
```

And the expectation over the ppd is plotted below, along with a loess curve for comparison. This model is clearly a better fit to the data than the linear model.

```{r}

p1 <- plot_nonlinear(mdl3, prob=0.89) +
  geom_point(mapping=aes(x=disp, y=mpg-mean(mpg), color=factor(cyl)),
             data=mtcars) +
  labs(title="GAM", x="disp", y="mpg-mean(mpg)")

p2 <- ggplot(mapping=aes(x=disp, y=mpg-mean(mpg)),
              data=mtcars) +
  geom_point(aes(color=factor(cyl)))+
  stat_smooth(method="loess",
              level=0.89) +
  labs(title="LOESS")

grid.arrange(p1, p2)
```

